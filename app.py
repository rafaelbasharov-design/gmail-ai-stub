# app.py
from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import openai
import logging

logging.basicConfig(level=logging.INFO)

app = Flask(__name__)
# –î–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ä–∞–±–æ—Ç—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ä–∞–∑—Ä–µ—à–∞–µ–º CORS.
# –í production –º–æ–∂–Ω–æ —Å—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ origins.
CORS(app, resources={r"/*": {"origins": ["*"]}})

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π API –∫–ª–∏–µ–Ω—Ç–∞ openai (v0.27.x style)
openai.api_key = os.getenv("OPENAI_API_KEY")

@app.route("/", methods=["GET"])
def home():
    return jsonify({"message": "AI Gmail server active üöÄ", "status": "ok"})

@app.route("/generate", methods=["POST"])
def generate_reply():
    """
    –û–∂–∏–¥–∞–µ—Ç JSON: { "text": "...", "max_tokens": 200, "temperature": 0.7 }
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON: { "reply": "..." } –∏–ª–∏ { "error": "..."} —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º HTTP-–∫–æ–¥–æ–º.
    """
    try:
        data = request.get_json(force=True, silent=False)
    except Exception as e:
        return jsonify({"error": "Invalid JSON payload", "details": str(e)}), 400

    if not data or "text" not in data:
        return jsonify({"error": "Empty text"}), 400

    user_text = (data.get("text") or "").strip()
    if not user_text:
        return jsonify({"error": "Empty text"}), 400

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ ‚Äî –¥–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ payload
    model = data.get("model", "gpt-3.5-turbo")
    temperature = float(data.get("temperature", 0.7))
    max_tokens = int(data.get("max_tokens", 200))

    # –§–æ—Ä–º–∏—Ä—É–µ–º system prompt ‚Äî –º–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å
    system_prompt = data.get("system_prompt") or (
        "–¢—ã ‚Äî –≤–µ–∂–ª–∏–≤—ã–π –∏ –∫—Ä–∞—Ç–∫–∏–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–º–æ—â–∏ –≤ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—É—é –ø–æ—á—Ç—É."
    )

    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ChatCompletion.create (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å openai==0.27.x)
        completion = openai.ChatCompletion.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_text}
            ],
            temperature=temperature,
            max_tokens=max_tokens,
            n=1
        )

        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞
        reply = ""
        if completion and getattr(completion, "choices", None):
            choice = completion.choices[0]
            # —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: choice.message.content (–¥–ª—è chat)
            if getattr(choice, "message", None) and choice.message.get("content"):
                reply = choice.message["content"].strip()
            elif getattr(choice, "text", None):
                reply = choice.text.strip()

        if not reply:
            return jsonify({"error": "Empty reply from model", "raw": completion}), 500

        return jsonify({"reply": reply})

    except openai.error.APIError as e:
        logging.exception("OpenAI APIError")
        return jsonify({"error": f"OpenAI APIError: {str(e)}"}), 502
    except openai.error.RateLimitError as e:
        logging.exception("OpenAI RateLimitError")
        return jsonify({"error": f"OpenAI RateLimitError: {str(e)}"}), 429
    except openai.error.InvalidRequestError as e:
        logging.exception("OpenAI InvalidRequestError")
        return jsonify({"error": f"OpenAI InvalidRequestError: {str(e)}"}), 400
    except Exception as e:
        logging.exception("Unexpected server error")
        return jsonify({"error": f"Server error: {str(e)}"}), 500

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port, debug=False)
